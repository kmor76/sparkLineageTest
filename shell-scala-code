val df3 = spark.read.option("delimiter", ",").option("header", "true").csv("s3a://kmor/customers-100.csv")
df3.show()

val df4 = spark.read.option("delimiter", ",").option("header", "true").parquet("s3a://kmor/userdata1.parquet")
df4.show()
val df5=df4.limit(10)
df5.write.format("parquet").option("header","true").mode("Overwrite").save("s3a://kmor/userdata1_filtered.parquet")

CREATE TEMPORARY VIEW userdata1
USING org.apache.spark.sql.parquet
OPTIONS (
  path "s3a://kmor/userdata1.parquet"
);


CREATE TABLE userdata1_filtered
USING org.apache.spark.sql.parquet
OPTIONS (
  path "s3a://kmor/userdata1_filtered.parquet"
)
AS SELECT * FROM userdata1 LIMIT 10;








CREATE TABLE userdata1
USING org.apache.spark.sql.parquet
OPTIONS (
  path "s3a://kmor/userdata1.parquet"
);


CREATE TABLE userdata1_filtered
USING org.apache.spark.sql.parquet
OPTIONS (
  path "s3a://kmor/userdata1_filtered.parquet"
)
AS SELECT * FROM userdata1 LIMIT 10;